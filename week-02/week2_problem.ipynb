{"cells":[{"cell_type":"markdown","metadata":{"id":"4dBGDz813T1S"},"source":["# COMP0189: Applied Artificial Intelligence\n","## Week 3 (Model Selection and Assessment)\n","\n","### After this week you will be able to ...\n","- encode categorical values with one-hot encoding\n","- know which encoding, scaling, and imputing method you should select in accordacne with the dataset characteristics\n","- impute missing data with KNN\n","- know how to streamline the preprocessing steps in advanced way (Pipeline and ColmnTransformer)\n","- perform model selection using different cross-validation methods\n","- perform model selection and model assessment using different partitions of the data\n","\n","### Acknowledgements\n","- https://scikit-learn.org/stable/\n","- https://archive.ics.uci.edu/ml/datasets/adult"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":535,"status":"ok","timestamp":1705419521079,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"4zs3aDLr3T1U"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"wO-p9am_3T1U"},"source":["## Part 1: Encoding and Imputations"]},{"cell_type":"markdown","metadata":{"id":"Jafyf6di3T1U"},"source":["### Task 1: Load and Split the Dataset into train and test"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1705419522107,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"ve7h01Bx3T1U","outputId":"236c4871-89f4-4b2c-ac52-87772a17ad9e","scrolled":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Workclass</th>\n","      <th>Fnlwgt</th>\n","      <th>Education</th>\n","      <th>Education-num</th>\n","      <th>Marital-status</th>\n","      <th>Occupation</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","      <th>Capital-gain</th>\n","      <th>Capital-loss</th>\n","      <th>Hours-per-week</th>\n","      <th>Native-country</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32556</th>\n","      <td>27</td>\n","      <td>Private</td>\n","      <td>257302</td>\n","      <td>Assoc-acdm</td>\n","      <td>12</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Tech-support</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32557</th>\n","      <td>40</td>\n","      <td>Private</td>\n","      <td>154374</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","    <tr>\n","      <th>32558</th>\n","      <td>58</td>\n","      <td>Private</td>\n","      <td>151910</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Widowed</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32559</th>\n","      <td>22</td>\n","      <td>Private</td>\n","      <td>201490</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32560</th>\n","      <td>52</td>\n","      <td>Self-emp-inc</td>\n","      <td>287927</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>15024</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32561 rows Ã— 15 columns</p>\n","</div>"],"text/plain":["       Age         Workclass  Fnlwgt   Education  Education-num  \\\n","0       39         State-gov   77516   Bachelors             13   \n","1       50  Self-emp-not-inc   83311   Bachelors             13   \n","2       38           Private  215646     HS-grad              9   \n","3       53           Private  234721        11th              7   \n","4       28           Private  338409   Bachelors             13   \n","...    ...               ...     ...         ...            ...   \n","32556   27           Private  257302  Assoc-acdm             12   \n","32557   40           Private  154374     HS-grad              9   \n","32558   58           Private  151910     HS-grad              9   \n","32559   22           Private  201490     HS-grad              9   \n","32560   52      Self-emp-inc  287927     HS-grad              9   \n","\n","           Marital-status         Occupation   Relationship    Race     Sex  \\\n","0           Never-married       Adm-clerical  Not-in-family   White    Male   \n","1      Married-civ-spouse    Exec-managerial        Husband   White    Male   \n","2                Divorced  Handlers-cleaners  Not-in-family   White    Male   \n","3      Married-civ-spouse  Handlers-cleaners        Husband   Black    Male   \n","4      Married-civ-spouse     Prof-specialty           Wife   Black  Female   \n","...                   ...                ...            ...     ...     ...   \n","32556  Married-civ-spouse       Tech-support           Wife   White  Female   \n","32557  Married-civ-spouse  Machine-op-inspct        Husband   White    Male   \n","32558             Widowed       Adm-clerical      Unmarried   White  Female   \n","32559       Never-married       Adm-clerical      Own-child   White    Male   \n","32560  Married-civ-spouse    Exec-managerial           Wife   White  Female   \n","\n","       Capital-gain  Capital-loss  Hours-per-week Native-country      Y  \n","0              2174             0              40  United-States  <=50K  \n","1                 0             0              13  United-States  <=50K  \n","2                 0             0              40  United-States  <=50K  \n","3                 0             0              40  United-States  <=50K  \n","4                 0             0              40           Cuba  <=50K  \n","...             ...           ...             ...            ...    ...  \n","32556             0             0              38  United-States  <=50K  \n","32557             0             0              40  United-States   >50K  \n","32558             0             0              40  United-States  <=50K  \n","32559             0             0              20  United-States  <=50K  \n","32560         15024             0              40  United-States   >50K  \n","\n","[32561 rows x 15 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# TASK 1: Load Dataset\n","# We are going to use the same adult dataset as previous week.\n","# We have cleaned the dataset, but did not touch the missing values.\n","from sklearn.model_selection import train_test_split\n","df = pd.read_csv(\"clean_adult.csv\")\n","df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sorted(list(df[\"Education-num\"].unique()))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["16"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(df[\"Education\"].unique())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df = df.drop(columns=[\"Education\"], axis=1) \n","# remove Education column since its label encoded version is already present."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Workclass</th>\n","      <th>Fnlwgt</th>\n","      <th>Education-num</th>\n","      <th>Marital-status</th>\n","      <th>Occupation</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","      <th>Capital-gain</th>\n","      <th>Capital-loss</th>\n","      <th>Hours-per-week</th>\n","      <th>Native-country</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32556</th>\n","      <td>27</td>\n","      <td>Private</td>\n","      <td>257302</td>\n","      <td>12</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Tech-support</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32557</th>\n","      <td>40</td>\n","      <td>Private</td>\n","      <td>154374</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","    <tr>\n","      <th>32558</th>\n","      <td>58</td>\n","      <td>Private</td>\n","      <td>151910</td>\n","      <td>9</td>\n","      <td>Widowed</td>\n","      <td>Adm-clerical</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32559</th>\n","      <td>22</td>\n","      <td>Private</td>\n","      <td>201490</td>\n","      <td>9</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>32560</th>\n","      <td>52</td>\n","      <td>Self-emp-inc</td>\n","      <td>287927</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>Female</td>\n","      <td>15024</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&gt;50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32561 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["       Age         Workclass  Fnlwgt  Education-num      Marital-status  \\\n","0       39         State-gov   77516             13       Never-married   \n","1       50  Self-emp-not-inc   83311             13  Married-civ-spouse   \n","2       38           Private  215646              9            Divorced   \n","3       53           Private  234721              7  Married-civ-spouse   \n","4       28           Private  338409             13  Married-civ-spouse   \n","...    ...               ...     ...            ...                 ...   \n","32556   27           Private  257302             12  Married-civ-spouse   \n","32557   40           Private  154374              9  Married-civ-spouse   \n","32558   58           Private  151910              9             Widowed   \n","32559   22           Private  201490              9       Never-married   \n","32560   52      Self-emp-inc  287927              9  Married-civ-spouse   \n","\n","              Occupation   Relationship    Race     Sex  Capital-gain  \\\n","0           Adm-clerical  Not-in-family   White    Male          2174   \n","1        Exec-managerial        Husband   White    Male             0   \n","2      Handlers-cleaners  Not-in-family   White    Male             0   \n","3      Handlers-cleaners        Husband   Black    Male             0   \n","4         Prof-specialty           Wife   Black  Female             0   \n","...                  ...            ...     ...     ...           ...   \n","32556       Tech-support           Wife   White  Female             0   \n","32557  Machine-op-inspct        Husband   White    Male             0   \n","32558       Adm-clerical      Unmarried   White  Female             0   \n","32559       Adm-clerical      Own-child   White    Male             0   \n","32560    Exec-managerial           Wife   White  Female         15024   \n","\n","       Capital-loss  Hours-per-week Native-country      Y  \n","0                 0              40  United-States  <=50K  \n","1                 0              13  United-States  <=50K  \n","2                 0              40  United-States  <=50K  \n","3                 0              40  United-States  <=50K  \n","4                 0              40           Cuba  <=50K  \n","...             ...             ...            ...    ...  \n","32556             0              38  United-States  <=50K  \n","32557             0              40  United-States   >50K  \n","32558             0              40  United-States  <=50K  \n","32559             0              20  United-States  <=50K  \n","32560             0              40  United-States   >50K  \n","\n","[32561 rows x 14 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def train_test_split_df(df, test_size = 0.1, target_cols = [\"Y\"]):\n","    \"\"\"\n","    This function splits the dataframe into train and test sets.\n","    It also separates the target column from the feature columns.\n","    \"\"\"\n","    df_data = df.drop(columns=target_cols, axis=1)\n","    df_target = df[target_cols]\n","\n","    split_index = int((1 - test_size) * len(df_data))\n","\n","    train_X_df = df_data[:split_index]\n","    train_Y_df = df_target[:split_index]\n","    test_X_df = df_data[split_index:]\n","    test_Y_df = df_target[split_index:]\n","\n","    train_Y_df = np.where(train_Y_df == \"<=50K\", 0, 1)\n","    test_Y_df = np.where(test_Y_df == \"<=50K\", 0, 1)\n","\n","    return train_X_df, train_Y_df, test_X_df, test_Y_df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_X_df, train_Y_df, test_X_df, test_Y_df = train_test_split_df(df) # splits the data into train and test sets."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["for col in train_X_df:\n","\n","    if col in [\n","        \"Age\",\n","        \"Fnlwgt\",\n","        \"Capital-gain\",\n","        \"Capital-loss\",\n","        \"Hours-per-week\"\n","    ]:\n","        continue\n","    train_uniq_vals = train_X_df[col].unique()\n","    test_uniq_vals = test_X_df[col].unique()\n","\n","    if not set(test_uniq_vals).issubset(set(train_uniq_vals)): \n","        # False: test has unexpected elements not present in the training set.\n","        print(col, \"has values that are not in train set\")"]},{"cell_type":"markdown","metadata":{"id":"JsLy5kau3T1U"},"source":["### Task 2: Encode categorical variables (label/ordinal encoding & one-hot encoding)"]},{"cell_type":"markdown","metadata":{"id":"bwd_77To3T1U"},"source":["### Important: We need special care when we are encoding categorical variables\n","\n","**1. Take care of the missing values**\n","- Beware not to encode missing values unless you are intending to do so.\n","- Sometimes you want to encode missing values to a separate cateogory. For example, when you want to predict if passengers of titanic had survived or not, missing data of certain features can actually have meaning, i.e., Cabin information can be missing because the body was not found.\n","\n","**2. Know which encoding and scaling method you should select**\n","- If your categories are ordinal, then it makes sense to use a LabelEncoder with a MinMaxScaler. For example, you can encode [low, medium, high], as [1,2,3], i.e., distance between low to high is larger than that of medium and high.\n","\n","- However, if you have non-ordinal categorical values, like [White, Hispanic, Black, Asian], then it would be better to use a OneHotEncoder instead of forcing ordinality with a LabelEncoder. Otherwise the algorithms you use (especially distance based algorithms like KNN) will make the assumption that the distance between White and Asian is larger than White and Hispanic, which is nonsensical.\n","\n","**3. Split before you encode to avoid data leakage**\n","- Split the dataset before you encode your data. It is natural for algorithms to see unknown values in the validation/test set that was not appearing in the train set. `sklearn.preprocessing.OneHotEncoder` is good at handling these unknown categories (`handle_unknown` parameter).\n","\n","- Discussion: What if you are certain about all the possible categories that can appear for each feature? Can you encode all the values before splitting the dataset into train and test set?\n","\n","\n","This notebook shows the three points in the following sections with examples."]},{"cell_type":"markdown","metadata":{"id":"HJ55CYB03T1U"},"source":["### Task 2-1: Label Encoding (with missing values)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705419522108,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"ldCwrFlm3T1V"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n","\n","label_encoder = LabelEncoder()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# display the columns\n","ordinal_columns = ['Education', 'Education-num', 'Marital-status', 'Relationship',\n","                   'Race', 'Sex']"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["label_encoded_df = df.copy()\n","label_encoded_df[ordinal_columns] = df[ordinal_columns].apply(label_encoder.fit_transform)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Education</th>\n","      <th>Education-num</th>\n","      <th>Marital-status</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32556</th>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>32557</th>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32558</th>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>32559</th>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32560</th>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32561 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["       Education  Education-num  Marital-status  Relationship  Race  Sex\n","0              9             12               4             1     4    1\n","1              9             12               2             0     4    1\n","2             11              8               0             1     4    1\n","3              1              6               2             0     2    1\n","4              9             12               2             5     2    0\n","...          ...            ...             ...           ...   ...  ...\n","32556          7             11               2             5     4    0\n","32557         11              8               2             0     4    1\n","32558         11              8               6             4     4    0\n","32559         11              8               4             3     4    1\n","32560         11              8               2             5     4    0\n","\n","[32561 rows x 6 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["label_encoded_df[ordinal_columns]"]},{"cell_type":"markdown","metadata":{"id":"h3m1FGN33T1V"},"source":["### Task 2-2: One Hot Encoding (with missing values imputation)\n","\n","Tip 1: Impute the missing values (choose the right strategy) before doing OHE  \n","Tip 2: Try creating a separate dataframe with one-hot encoded columns and combine the dataframe with the original dataframe for the final one."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1705419522417,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"lo19duKZ3T1V"},"outputs":[],"source":["# Let's first impute the missing values.\n","# Since it's a categorical value, we don't use KNN or mean imputation.\n","# We will replace with the most frequent value.\n","from sklearn.impute import SimpleImputer\n","\n","# most frequent imputation since the method could be used for both string \n","# and numerical columns. \n","mode_imputer = SimpleImputer(strategy='most_frequent')\n","\n","missing_columns = df.columns\n","\n","missing_df = df.copy()\n","\n","missing_df[missing_columns] = mode_imputer.fit_transform(df)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1705419522726,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"FiI8nZ6T3dgS","outputId":"ea5d666a-6b6d-4501-df77-28a6fff8c4f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Age               0\n","Workclass         0\n","Fnlwgt            0\n","Education         0\n","Education-num     0\n","Marital-status    0\n","Occupation        0\n","Relationship      0\n","Race              0\n","Sex               0\n","Capital-gain      0\n","Capital-loss      0\n","Hours-per-week    0\n","Native-country    0\n","Y                 0\n","dtype: int64\n"]}],"source":["print(missing_df.isnull().sum())"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1705419886383,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"PJkNW7hZ8jU8","outputId":"c37532c3-44e6-435e-bb77-869583e963d1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Workclass</th>\n","      <th>Fnlwgt</th>\n","      <th>Education</th>\n","      <th>Education-num</th>\n","      <th>Marital-status</th>\n","      <th>Occupation</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","      <th>Capital-gain</th>\n","      <th>Capital-loss</th>\n","      <th>Hours-per-week</th>\n","      <th>Native-country</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>Cuba</td>\n","      <td>&lt;=50K</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Age         Workclass  Fnlwgt  Education Education-num      Marital-status  \\\n","0  39         State-gov   77516  Bachelors            13       Never-married   \n","1  50  Self-emp-not-inc   83311  Bachelors            13  Married-civ-spouse   \n","2  38           Private  215646    HS-grad             9            Divorced   \n","3  53           Private  234721       11th             7  Married-civ-spouse   \n","4  28           Private  338409  Bachelors            13  Married-civ-spouse   \n","\n","          Occupation   Relationship    Race     Sex Capital-gain Capital-loss  \\\n","0       Adm-clerical  Not-in-family   White    Male         2174            0   \n","1    Exec-managerial        Husband   White    Male            0            0   \n","2  Handlers-cleaners  Not-in-family   White    Male            0            0   \n","3  Handlers-cleaners        Husband   Black    Male            0            0   \n","4     Prof-specialty           Wife   Black  Female            0            0   \n","\n","  Hours-per-week Native-country      Y  \n","0             40  United-States  <=50K  \n","1             13  United-States  <=50K  \n","2             40  United-States  <=50K  \n","3             40  United-States  <=50K  \n","4             40           Cuba  <=50K  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["missing_df.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":200,"status":"ok","timestamp":1705419638636,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"FCfgUnqw7X7o"},"outputs":[],"source":["onehot_encoder = OneHotEncoder()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1705420163025,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"zP5tolxw7PFF"},"outputs":[],"source":["def apply_onehot_encoding(df, columns):\n","    # Perform One-Hot Encoding\n","    encoded_data = onehot_encoder.fit_transform(df[columns]).toarray()\n","    column_names = onehot_encoder.get_feature_names_out(columns)\n","    df_encoded = pd.DataFrame(encoded_data, columns=column_names)\n","\n","    # Reset indices to ensure alignment\n","    df_reset = df.reset_index(drop=True)\n","    df_encoded_reset = df_encoded.reset_index(drop=True)\n","\n","    # Drop original columns and concatenate the new One-Hot Encoded columns\n","    return pd.concat([df_reset.drop(columns, axis=1), df_encoded_reset], axis=1)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":196,"status":"ok","timestamp":1705420272364,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"DjUV7nNi7pbr"},"outputs":[],"source":["# categorical_columns = ['Workclass', 'Occupation', 'Native-country']\n","# experiment the code with the every categorical columns from the dataset\n","categorical_columns = ['Workclass', 'Education', 'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Native-country']"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1705420273463,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"Sm4dU2He8TRl"},"outputs":[],"source":["onehot_encoded_df = apply_onehot_encoding(missing_df, categorical_columns)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"elapsed":408,"status":"ok","timestamp":1705420274377,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"VtmRUJi-8csM","outputId":"7f4446c4-59a7-4ea8-fdb7-786e5f70fca4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Fnlwgt</th>\n","      <th>Education-num</th>\n","      <th>Capital-gain</th>\n","      <th>Capital-loss</th>\n","      <th>Hours-per-week</th>\n","      <th>Y</th>\n","      <th>Workclass_Federal-gov</th>\n","      <th>Workclass_Local-gov</th>\n","      <th>Workclass_Never-worked</th>\n","      <th>...</th>\n","      <th>Native-country_Portugal</th>\n","      <th>Native-country_Puerto-Rico</th>\n","      <th>Native-country_Scotland</th>\n","      <th>Native-country_South</th>\n","      <th>Native-country_Taiwan</th>\n","      <th>Native-country_Thailand</th>\n","      <th>Native-country_Trinadad&amp;Tobago</th>\n","      <th>Native-country_United-States</th>\n","      <th>Native-country_Vietnam</th>\n","      <th>Native-country_Yugoslavia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>77516</td>\n","      <td>13</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>&lt;=50K</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>83311</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>&lt;=50K</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>215646</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>&lt;=50K</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>234721</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>&lt;=50K</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>338409</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>&lt;=50K</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 106 columns</p>\n","</div>"],"text/plain":["  Age  Fnlwgt Education-num Capital-gain Capital-loss Hours-per-week      Y  \\\n","0  39   77516            13         2174            0             40  <=50K   \n","1  50   83311            13            0            0             13  <=50K   \n","2  38  215646             9            0            0             40  <=50K   \n","3  53  234721             7            0            0             40  <=50K   \n","4  28  338409            13            0            0             40  <=50K   \n","\n","   Workclass_Federal-gov  Workclass_Local-gov  Workclass_Never-worked  ...  \\\n","0                    0.0                  0.0                     0.0  ...   \n","1                    0.0                  0.0                     0.0  ...   \n","2                    0.0                  0.0                     0.0  ...   \n","3                    0.0                  0.0                     0.0  ...   \n","4                    0.0                  0.0                     0.0  ...   \n","\n","   Native-country_Portugal  Native-country_Puerto-Rico  \\\n","0                      0.0                         0.0   \n","1                      0.0                         0.0   \n","2                      0.0                         0.0   \n","3                      0.0                         0.0   \n","4                      0.0                         0.0   \n","\n","   Native-country_Scotland  Native-country_South  Native-country_Taiwan  \\\n","0                      0.0                   0.0                    0.0   \n","1                      0.0                   0.0                    0.0   \n","2                      0.0                   0.0                    0.0   \n","3                      0.0                   0.0                    0.0   \n","4                      0.0                   0.0                    0.0   \n","\n","   Native-country_Thailand  Native-country_Trinadad&Tobago  \\\n","0                      0.0                             0.0   \n","1                      0.0                             0.0   \n","2                      0.0                             0.0   \n","3                      0.0                             0.0   \n","4                      0.0                             0.0   \n","\n","   Native-country_United-States  Native-country_Vietnam  \\\n","0                           1.0                     0.0   \n","1                           1.0                     0.0   \n","2                           1.0                     0.0   \n","3                           1.0                     0.0   \n","4                           0.0                     0.0   \n","\n","   Native-country_Yugoslavia  \n","0                        0.0  \n","1                        0.0  \n","2                        0.0  \n","3                        0.0  \n","4                        0.0  \n","\n","[5 rows x 106 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["onehot_encoded_df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["final_df = pd.concat([df, onehot_encoded_df], axis=1) # combines the original dataframe with the onehot encoded dataframe for a dataset that contains all the needed information. "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Workclass</th>\n","      <th>Fnlwgt</th>\n","      <th>Education</th>\n","      <th>Education-num</th>\n","      <th>Marital-status</th>\n","      <th>Occupation</th>\n","      <th>Relationship</th>\n","      <th>Race</th>\n","      <th>Sex</th>\n","      <th>...</th>\n","      <th>Native-country_Portugal</th>\n","      <th>Native-country_Puerto-Rico</th>\n","      <th>Native-country_Scotland</th>\n","      <th>Native-country_South</th>\n","      <th>Native-country_Taiwan</th>\n","      <th>Native-country_Thailand</th>\n","      <th>Native-country_Trinadad&amp;Tobago</th>\n","      <th>Native-country_United-States</th>\n","      <th>Native-country_Vietnam</th>\n","      <th>Native-country_Yugoslavia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>53</td>\n","      <td>Private</td>\n","      <td>234721</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Husband</td>\n","      <td>Black</td>\n","      <td>Male</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28</td>\n","      <td>Private</td>\n","      <td>338409</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Prof-specialty</td>\n","      <td>Wife</td>\n","      <td>Black</td>\n","      <td>Female</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 121 columns</p>\n","</div>"],"text/plain":["   Age         Workclass  Fnlwgt  Education  Education-num  \\\n","0   39         State-gov   77516  Bachelors             13   \n","1   50  Self-emp-not-inc   83311  Bachelors             13   \n","2   38           Private  215646    HS-grad              9   \n","3   53           Private  234721       11th              7   \n","4   28           Private  338409  Bachelors             13   \n","\n","       Marital-status         Occupation   Relationship    Race     Sex  ...  \\\n","0       Never-married       Adm-clerical  Not-in-family   White    Male  ...   \n","1  Married-civ-spouse    Exec-managerial        Husband   White    Male  ...   \n","2            Divorced  Handlers-cleaners  Not-in-family   White    Male  ...   \n","3  Married-civ-spouse  Handlers-cleaners        Husband   Black    Male  ...   \n","4  Married-civ-spouse     Prof-specialty           Wife   Black  Female  ...   \n","\n","   Native-country_Portugal  Native-country_Puerto-Rico  \\\n","0                      0.0                         0.0   \n","1                      0.0                         0.0   \n","2                      0.0                         0.0   \n","3                      0.0                         0.0   \n","4                      0.0                         0.0   \n","\n","   Native-country_Scotland Native-country_South Native-country_Taiwan  \\\n","0                      0.0                  0.0                   0.0   \n","1                      0.0                  0.0                   0.0   \n","2                      0.0                  0.0                   0.0   \n","3                      0.0                  0.0                   0.0   \n","4                      0.0                  0.0                   0.0   \n","\n","  Native-country_Thailand Native-country_Trinadad&Tobago  \\\n","0                     0.0                            0.0   \n","1                     0.0                            0.0   \n","2                     0.0                            0.0   \n","3                     0.0                            0.0   \n","4                     0.0                            0.0   \n","\n","  Native-country_United-States Native-country_Vietnam  \\\n","0                          1.0                    0.0   \n","1                          1.0                    0.0   \n","2                          1.0                    0.0   \n","3                          1.0                    0.0   \n","4                          0.0                    0.0   \n","\n","  Native-country_Yugoslavia  \n","0                       0.0  \n","1                       0.0  \n","2                       0.0  \n","3                       0.0  \n","4                       0.0  \n","\n","[5 rows x 121 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["final_df.head()"]},{"cell_type":"markdown","metadata":{"id":"Jq9UcXG_3T1V"},"source":["### Side Note: Data Imputation with KNN\n","For the adult dataset, missing data present only in categorical values, so imputing strategy that makes floating point may not make sense.\n","However, for continuous values, you can use various imputation strategies, such as taking simple mean or mean value from K nearest neighbors (KNN).\n","If you use `sklearn.imput.KNNImputer`, each sampleâ€™s missing values are imputed using the `mean` value from `n_neighbors` nearest neighbors found in the training set.\n","If you want to use `mode` value from neighbors (for categorical data imputation) you need to implement the imputer by yourself.\n","\n","- `sklearn-pandas` package (https://pypi.org/project/sklearn-pandas/1.5.0/) provides `CategoricalImputer` class, which is suitable for such processing\n","\n","Here, we use iris dataset to show how to use KNNImputer for continuous values"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":208,"status":"ok","timestamp":1705420292408,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"r1HdQol83T1V"},"outputs":[],"source":["from sklearn.datasets import load_iris\n","from sklearn.impute import KNNImputer"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705420293064,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"EHuO1A9V3T1V"},"outputs":[],"source":["iris = load_iris()\n","iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1705420294480,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"RjO8yQ073T1W","outputId":"0a303d1c-ac93-4b3a-a789-d04ab89b041e"},"outputs":[{"data":{"text/plain":["sepal length (cm)    17\n","sepal width (cm)      8\n","petal length (cm)    14\n","petal width (cm)     15\n","dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Applying a random mask to make missing data\n","mask = np.random.choice([True, False], size=iris_df.shape[0] * iris_df.shape[1])\n","mask[:500] = True\n","np.random.shuffle(mask)\n","mask = np.reshape(mask, iris_df.shape)\n","iris_df = iris_df.mask(~mask)\n","\n","iris_df.isnull().sum()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1705420296165,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"MorQQd4V3T1W"},"outputs":[],"source":["train_X, test_X = iris_df[:100], iris_df[100:]"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705420296861,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"zkh5aI_J3T1W"},"outputs":[],"source":["# It is important to impute the train and test set separately (not fitting KNN to test set) to avoid data leak.\n","imputer = KNNImputer(n_neighbors=5)\n","imputed_train_X = imputer.fit_transform(train_X)\n","imputed_test_X = imputer.transform(test_X)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705420297658,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"YgJNUSFP3T1W"},"outputs":[],"source":["del iris, iris_df, mask, train_X, test_X, imputer, imputed_train_X, imputed_test_X"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705418605535,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"JjqvhZ0j3T1W"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6xa4zDSc3T1W"},"source":["### Task 3: Create different preprocessing strategies of your own\n","Create different versions of X (X1 and X2) by dropping missing values (X1) or using strategies for data imputation (X2). Define different preprocessing strategies using the `Pipeline` and `ColmnTransformer` class\n"]},{"cell_type":"markdown","metadata":{"id":"1-fmKg3FnoNL"},"source":["### Task 3-1: Dropping missing values (X1)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1705420301448,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"OwD6VO-S3T1W"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.preprocessing import StandardScaler\n","non_categorical_features = [\n","    \"Age\",\n","    \"Fnlwgt\",\n","    \"Capital-gain\",\n","    \"Capital-loss\",\n","    \"Hours-per-week\",\n","]\n","categorical_ohe_features = [\n","    \"Workclass\",\n","    \"Education-num\",\n","    \"Marital-status\",\n","    \"Occupation\",\n","    \"Relationship\",\n","    \"Race\",\n","    \"Native-country\",\n","]\n","categorical_le_features = [\"Sex\"]"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705420302181,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"vevvJZk73T1W","outputId":"e403492e-d177-4607-fc97-e95b59b4acd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Workclass', 'Occupation', 'Native-country'], dtype='object')\n"]}],"source":["# Your explorations here\n","\n","print(df.columns[df.isnull().any()])"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":205,"status":"ok","timestamp":1705420340665,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"ztpBflEbpAkh"},"outputs":[],"source":["X1 = df.dropna() # creates a dataframe, X1 that drops the null values."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":519,"status":"ok","timestamp":1705420350312,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"itHc27bK-UUK","outputId":"ff7ee52b-398c-40df-b852-36c4a5ec0dca"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 30162 entries, 0 to 32560\n","Data columns (total 15 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   Age             30162 non-null  int64 \n"," 1   Workclass       30162 non-null  object\n"," 2   Fnlwgt          30162 non-null  int64 \n"," 3   Education       30162 non-null  object\n"," 4   Education-num   30162 non-null  int64 \n"," 5   Marital-status  30162 non-null  object\n"," 6   Occupation      30162 non-null  object\n"," 7   Relationship    30162 non-null  object\n"," 8   Race            30162 non-null  object\n"," 9   Sex             30162 non-null  object\n"," 10  Capital-gain    30162 non-null  int64 \n"," 11  Capital-loss    30162 non-null  int64 \n"," 12  Hours-per-week  30162 non-null  int64 \n"," 13  Native-country  30162 non-null  object\n"," 14  Y               30162 non-null  object\n","dtypes: int64(6), object(9)\n","memory usage: 3.7+ MB\n"]}],"source":["X1.info()"]},{"cell_type":"markdown","metadata":{"id":"tkS0IA9YeZfe"},"source":["#### Task 3-1: Using strategies for data imputation (X2)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1705420557637,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"uYXv6crkhjU6"},"outputs":[],"source":["categorical_features_with_na = ['Workclass', 'Occupation', 'Native-country']\n","numerical_features = ['Age', 'Fnlwgt', 'Education-num', 'Capital-gain', 'Capital-loss', 'Hours-per-week']\n","categorical_features_without_na = ['Education', 'Marital-status', 'Relationship', 'Race', 'Sex']"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1705420601062,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"XdwfFqCw_JOL"},"outputs":[],"source":["categorical_imputer = SimpleImputer(strategy='most_frequent')\n","categorical_pipeline = Pipeline(steps=[\n","    ('imputer', categorical_imputer),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1705420706085,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"jTwc8aa1_VKb"},"outputs":[],"source":["numerical_scaler = StandardScaler()\n","numerical_pipeline = Pipeline(steps=[\n","    ('scaler', numerical_scaler)\n","])"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1705420716295,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"v4T9Uzu1_tND"},"outputs":[],"source":["# Combining transformers for the ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_pipeline, numerical_features),\n","        ('cat_impute_ohe', categorical_pipeline, categorical_features_with_na),\n","        ('cat_ohe', OneHotEncoder(handle_unknown='ignore'), categorical_features_without_na)\n","    ]\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1705421001832,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"x9QAp90Y_yNS"},"outputs":[],"source":["X2_matrix = preprocessor.fit_transform(df)\n","X2_array = X2_matrix.toarray()\n","X2 = pd.DataFrame(X2_array)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705421009516,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"vE3ZmFhhAF6D","outputId":"74a27686-3e32-4845-8129-5fc48ba4a274"},"outputs":[{"data":{"text/plain":["pandas.core.frame.DataFrame"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["type(X2)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1705421017239,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"_BExDbYLA3wM","outputId":"af196fba-faca-49a0-f5e8-ce63194f49f9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.030671</td>\n","      <td>-1.063611</td>\n","      <td>1.134739</td>\n","      <td>0.148453</td>\n","      <td>-0.21666</td>\n","      <td>-0.035429</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.837109</td>\n","      <td>-1.008707</td>\n","      <td>1.134739</td>\n","      <td>-0.145920</td>\n","      <td>-0.21666</td>\n","      <td>-2.222153</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.042642</td>\n","      <td>0.245079</td>\n","      <td>-0.420060</td>\n","      <td>-0.145920</td>\n","      <td>-0.21666</td>\n","      <td>-0.035429</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.057047</td>\n","      <td>0.425801</td>\n","      <td>-1.197459</td>\n","      <td>-0.145920</td>\n","      <td>-0.21666</td>\n","      <td>-0.035429</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.775768</td>\n","      <td>1.408176</td>\n","      <td>1.134739</td>\n","      <td>-0.145920</td>\n","      <td>-0.21666</td>\n","      <td>-0.035429</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 105 columns</p>\n","</div>"],"text/plain":["        0         1         2         3        4         5    6    7    8    \\\n","0  0.030671 -1.063611  1.134739  0.148453 -0.21666 -0.035429  0.0  0.0  0.0   \n","1  0.837109 -1.008707  1.134739 -0.145920 -0.21666 -2.222153  0.0  0.0  0.0   \n","2 -0.042642  0.245079 -0.420060 -0.145920 -0.21666 -0.035429  0.0  0.0  0.0   \n","3  1.057047  0.425801 -1.197459 -0.145920 -0.21666 -0.035429  0.0  0.0  0.0   \n","4 -0.775768  1.408176  1.134739 -0.145920 -0.21666 -0.035429  0.0  0.0  0.0   \n","\n","   9    ...  95   96   97   98   99   100  101  102  103  104  \n","0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n","1  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n","2  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n","3  1.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  \n","4  1.0  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n","\n","[5 rows x 105 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["X2.head()"]},{"cell_type":"markdown","metadata":{"id":"kyaIeYem3T1W"},"source":["### Task 4:\n","Train different models (KNN, SVM) to predict the y from the two versions of X (X1 and X2) with a fixed value of the regularization parameter.\n","Centre and scale the data before training the models. Create tables or plots to show how accuracy varies for different imputation strategies or different models."]},{"cell_type":"markdown","metadata":{"id":"x9KJk1D13T1W"},"source":["### Task 4-1: Training KNN and SVM Models with X1\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1705421215314,"user":{"displayName":"Haocheng Lin","userId":"03522302576311057283"},"user_tz":0},"id":"92fkl3413T1W"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import svm\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.feature_selection import mutual_info_classif"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"gGyQeojihmOg"},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors=5)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# split X1 into X and y \n","y = X1['Y']\n","X = X1.drop(['Y'], axis=1)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# only select the non-categorical features for X\n","X = X[non_categorical_features]"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["X_train = StandardScaler().fit_transform(X_train)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"],"text/plain":["KNeighborsClassifier()"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["knn.fit(X_train, y_train) # trains the training data on the KNN model. "]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\haoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n","  warnings.warn(\n"]}],"source":["# test the data on the knn model\n","y_pred = knn.predict(X_test)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def generate_report(y_test, y_pred):\n","    print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n","    print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n","    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n","    print(mutual_info_classif(X_train, y_train))"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score:  0.757334659373446\n","Confusion Matrix: \n"," [[4540    0]\n"," [1464   29]]\n","Classification Report: \n","               precision    recall  f1-score   support\n","\n","       <=50K       0.76      1.00      0.86      4540\n","        >50K       1.00      0.02      0.04      1493\n","\n","    accuracy                           0.76      6033\n","   macro avg       0.88      0.51      0.45      6033\n","weighted avg       0.82      0.76      0.66      6033\n","\n","[0.06593495 0.0244849  0.08479619 0.04068244 0.03819423]\n"]}],"source":["generate_report(y_test, y_pred)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["svm_model = svm.SVC()"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"],"text/plain":["SVC()"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["svm_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\haoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SVC was fitted without feature names\n","  warnings.warn(\n"]}],"source":["y_pred = svm_model.predict(X_test)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score:  0.75252776396486\n","Confusion Matrix: \n"," [[4540    0]\n"," [1493    0]]\n","Classification Report: \n","               precision    recall  f1-score   support\n","\n","       <=50K       0.75      1.00      0.86      4540\n","        >50K       0.00      0.00      0.00      1493\n","\n","    accuracy                           0.75      6033\n","   macro avg       0.38      0.50      0.43      6033\n","weighted avg       0.57      0.75      0.65      6033\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\haoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\haoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\haoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["[0.06982779 0.02470751 0.08644799 0.03165074 0.04136588]\n"]}],"source":["generate_report(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"uSX8D0on3T1W"},"source":["### Task 4-2: Training KNN and SVM Models with X2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dt31bb7Zhna7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TIIBj47c3T1W"},"source":["## Part 2: Cross Validation (CV)"]},{"cell_type":"markdown","metadata":{"id":"NjuVQrMm3T1W"},"source":["scikit-learn provides a nice visualisation of various cross validation methods.\n","This notebook focuses on different cross validation strategies and how to account for data structure during cross-validation.\n","\n","\n","Visit: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#visualizing-cross-validation-behavior-in-scikit-learn\n","\n","![kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_006.png)\n","![stra-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_003.png)\n","![group-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_004.png)\n","![stra-group-kfold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_010.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJyx1eZO3T1X"},"outputs":[],"source":["from sklearn.model_selection import (\n","    KFold,\n","    StratifiedKFold,\n","    GroupKFold,\n","    StratifiedGroupKFold,\n","    GridSearchCV,\n",")"]},{"cell_type":"markdown","metadata":{"id":"6yVJbC2E3T1X"},"source":["### Task 5\n","Now apply cross-validation to the train set (k=5) for optimizing the models hyperparameters. After identifying the best hyperparameter, measure the performance on the test data by training the models on the training data using the optimal hyperparameter. Note: remember that the pre-processing steps, including data centering and scaling should be embedded in the CV.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hsu9I18zhrJE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IJ7bezApwBd1"},"source":["#### Task 5-1\n","Plot the model performance (mean accuracy and SD) for different hyper-parameter values.\n","- How does the accuracy vary as function of the hyperparameter?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEHCwdvlhsU9"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"FgOmKtvefdbb"},"source":["#### Task 5-2\n","Print the average cross-validation score, the best cross-validation score, the best hyperparameter and the test-score.\n"," - Is there a difference between the average cross-validation score, the best cross-validation score and the test-score?\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoRgQ5KXhtHO"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"kJXSdDRS3T1X"},"source":["### Task 6\n","Repeat task 5 using stratified CV with k=5. Centre and scale the data before training the models. Print the average cross-validation score, the best cross-validation score, the best hyperparameter and the test-score.\n","\n","- Did the performances changes with the stratified CV?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUV9IHw9huJv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xacpzqp5xdSO"},"source":["### Task 7\n","Repeat task 5 using stratified group CV considering 'Race' as a group with k=5. Centre and scale the data before training the models. Print the average cross-validation score, the best cross-validation score, the best hyperparameter and the test-score.\n"," - Did the performances changes with the stratified group CV?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zmSsPSchvaa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"s7omJ16T3T1X"},"source":["### Task 8\n","Now implement a nested CV for optimize the modelsâ€™ hyper-parameters and assessing the modelsâ€™ performance (with k=5 for the inner and outer loop). The inner loop should optimize the modelsâ€™ hyper-parameters and the outer loop should assess the modelsâ€™ performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3Y4CJsPma8e"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"c975486aa82b32d30c2438da9d14334177c2b4d93822b75ed42b1917e361f4e6"}}},"nbformat":4,"nbformat_minor":0}
